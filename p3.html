<!DOCTYPE html>
<html>
<head>
	<title>title
</title>
</head>
<body>
	<h1 style="font-size: 33pz; color: blue">History of Artificial Intelligence

 <br>
<img style="width: 600; height: 100" src="what-is-artificial-intelligence_1.png">
 <br>
</h1>
    <p>1980-1990: Expert systems
In 1968 Stanley Kubrick directed the film "2001 Space Odyssey" where a computer - HAL 9000 (only one letter away from those of IBM) summarizes in itself the whole sum of ethical questions posed by AI: will it represent a high level of sophistication, a good for humanity or a danger? The impact of the film will naturally not be scientific but it will contribute to popularize the theme, just as the science fiction author Philip K. Dick, who will never cease to wonder if, one day, the machines will experience emotions.

It was with the advent of the first microprocessors at the end of 1970 that AI took off again and entered the golden age of expert systems.

The path was actually opened at MIT in 1965 with DENDRAL (expert system specialized in molecular chemistry) and at Stanford University in 1972 with MYCIN (system specialized in the diagnosis of blood diseases and prescription drugs). These systems were based on an "inference engine," which was programmed to be a logical mirror of human reasoning. By entering data, the engine provided answers of a high level of expertise.

The promises foresaw a massive development but the craze will fall again at the end of 1980, early 1990. The programming of such knowledge actually required a lot of effort and from 200 to 300 rules, there was a "black box" effect where it was not clear how the machine reasoned. Development and maintenance thus became extremely problematic and - above all - faster and in many other less complex and less expensive ways were possible. It should be recalled that in the 1990s, the term artificial intelligence had almost become taboo and more modest variations had even entered university language, such as "advanced computing".

The success in May 1997 of Deep Blue (IBM's expert system) at the chess game against Garry Kasparov fulfilled Herbert Simon's 1957 prophecy 30 years later but did not support the financing and development of this form of AI. The operation of Deep Blue was based on a systematic brute force algorithm, where all possible moves were evaluated and weighted. The defeat of the human remained very symbolic in the history but Deep Blue had in reality only managed to treat a very limited perimeter (that of the rules of the chess game), very far from the capacity to model the complexity of the world.

Since 2010: a new bloom based on massive data and new computing power
Two factors explain the new boom in the discipline around 2010.
<br>
        <img src="4.-The-Artificial-intelligence-examples-That-People-Havent-Realized.jpg">
        <br>

- First of all, access to massive volumes of data. To be able to use algorithms for image classification and cat recognition, for example, it was previously necessary to carry out sampling yourself. Today, a simple search on Google can find millions.

- Then the discovery of the very high efficiency of computer graphics card processors to accelerate the calculation of learning algorithms. The process being very iterative, it could take weeks before 2010 to process the entire sample. The computing power of these cards (capable of more than a thousand billion transactions per second) has enabled considerable progress at a limited financial cost (less than 1000 euros per card).

This new technological equipment has enabled some significant public successes and has boosted funding: in 2011, Watson, IBM's IA, will win the games against 2 Jeopardy champions! Â». In 2012, Google X (Google's search lab) will be able to have an AI recognize cats on a video. More than 16,000 processors have been used for this last task, but the potential is extraordinary: a machine learns to distinguish something. In 2016, AlphaGO (Google's AI specialized in Go games) will beat the European champion (Fan Hui) and the world champion (Lee Sedol) then herself (AlphaGo Zero). Let us specify that the game of Go has a combinatorics much more important than chess (more than the number of particles in the universe) and that it is not possible to have such significant results in raw strength (as for Deep Blue in 1997).

Where did this miracle come from? A complete paradigm shift from expert systems. The approach has become inductive: it is no longer a question of coding rules as for expert systems, but of letting computers discover them alone by correlation and classification, on the basis of a massive amount of data.

Among machine learning techniques, deep learning seems the most promising for a number of applications (including voice or image recognition). In 2003, Geoffrey Hinton (University of Toronto), Yoshua Bengio (University of Montreal) and Yann LeCun (University of New York) decided to start a research program to bring neural networks up to date. Experiments conducted simultaneously at Microsoft, Google and IBM with the help of the Toronto laboratory in Hinton showed that this type of learning succeeded in halving the error rates for speech recognition. Similar results were achieved by Hinton's image recognition team.

Overnight, a large majority of research teams turned to this technology with indisputable benefits. This type of learning has also enabled considerable progress in text recognition, but, according to experts like Yann LeCun, there is still a long way to go to produce text understanding systems. Conversational agents illustrate this challenge well: our smartphones already know how to transcribe an instruction but cannot fully contextualize it and analyze our intentions.
    </p>
	<h2>links</h2>
	<ul>
  <li><a href="index.html">main page</a></li>
  <li><a href="p1.html">Understanding Artificial Intelligence</a></li>
  <li><a href="p2.html">the difference between AI, Machine Learning and Deep Learning</a></li>
   <li><a href="p3.html">History of Artificial Intelligence /a></a></li>
   <li><a href="p4.html">Application of Artificial Intelligence</a></li>

    </ul>
</body>
</html>